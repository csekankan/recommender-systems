{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84eddad3",
      "metadata": {
        "id": "84eddad3"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import os\n",
        "import matplotlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "from scipy import sparse\n",
        "from scipy.sparse import csc_matrix\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGRD8a9sKacB"
      },
      "source": [
        "### Setup and Load dataset"
      ],
      "id": "uGRD8a9sKacB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6266078"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "from os.path import exists\n",
        "import zipfile\n",
        "import numpy as np"
      ],
      "id": "d6266078"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H54YO5cNfiWJ",
        "outputId": "9d1df05e-2f47-4760-e6b7-6abac041a9ea"
      },
      "id": "H54YO5cNfiWJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget  -b  https://files.grouplens.org/datasets/movielens/ml-25m.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmVtGeTeD2kb",
        "outputId": "574338a7-bf5f-4733-f42f-8a8631a39080"
      },
      "id": "PmVtGeTeD2kb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Continuing in background, pid 81400.\n",
            "Output will be written to ‘wget-log.5’.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget  -b  https://files.grouplens.org/datasets/movielens/ml-100k.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1r8Sraf7rPj",
        "outputId": "d82cfbb0-e9f4-42e9-a1c1-8e310f0b094a"
      },
      "id": "C1r8Sraf7rPj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Continuing in background, pid 81402.\n",
            "Output will be written to ‘wget-log.6’.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!gdown https://drive.google.com/uc?id=1iyh-mmcyBaMxZAk_Ey4ncW0mSPNKYcCn"
      ],
      "metadata": {
        "id": "JN6L-XVUpDB3"
      },
      "execution_count": null,
      "outputs": [],
      "id": "JN6L-XVUpDB3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_UJlmcgZNBc"
      },
      "source": [
        "### Setup"
      ],
      "id": "D_UJlmcgZNBc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcRlILa1ZNBc"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "from os.path import exists\n",
        "import zipfile\n",
        "import numpy as np"
      ],
      "id": "HcRlILa1ZNBc"
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o \"ml-1m.zip\"  -d  \"/content\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtZEDi2_JS0Z",
        "outputId": "63642ba1-b857-4c26-e760-3dd96fd8fcd2"
      },
      "id": "TtZEDi2_JS0Z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ml-1m.zip\n",
            "  inflating: /content/ml-1m/movies.dat  \n",
            "  inflating: /content/ml-1m/ratings.dat  \n",
            "  inflating: /content/ml-1m/README   \n",
            "  inflating: /content/ml-1m/users.dat  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('ml-1m/ratings.dat', sep='::', header=0, skipinitialspace=True)\n",
        "data.dropna(inplace=True)\n"
      ],
      "metadata": {
        "id": "srhJBCtkJaHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04531dde-a6eb-4be6-ee13-6d7a453b412b"
      },
      "id": "srhJBCtkJaHZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_10k_df = data"
      ],
      "metadata": {
        "id": "HMP14KjX9Xzc"
      },
      "id": "HMP14KjX9Xzc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_10k_df.columns =[ 'userID', 'itemID', 'rating','timestamp']"
      ],
      "metadata": {
        "id": "YbFQnPrW9k3C"
      },
      "id": "YbFQnPrW9k3C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# y = movie_10k_df.groupby('userID').count()['rating']>=200\n",
        "# ids = y[y].index\n",
        "# movie_10k_df = movie_10k_df[movie_10k_df['userID'].isin(ids)]\n",
        "\n",
        "# y = movie_10k_df.groupby('itemID').count()['rating']>=100\n",
        "# ids = y[y].index\n",
        "# movie_10k_df = movie_10k_df[movie_10k_df['itemID'].isin(ids)]"
      ],
      "metadata": {
        "id": "JDChOjCMjyaj"
      },
      "id": "JDChOjCMjyaj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_10k_df['userID']=movie_10k_df['userID'].astype(str)\n",
        "movie_10k_df['itemID']=movie_10k_df['itemID'].astype(str)"
      ],
      "metadata": {
        "id": "6XtlY9bij3Lb"
      },
      "id": "6XtlY9bij3Lb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(movie_10k_df['userID'].unique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJqu687Qhwp9",
        "outputId": "83b96d22-b30a-4219-f087-b20aefde1dfb"
      },
      "id": "lJqu687Qhwp9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6040"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(movie_10k_df['itemID'].unique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwhbybfNh2-m",
        "outputId": "c510e556-6e92-4cab-df11-fd1045b2c7ea"
      },
      "id": "CwhbybfNh2-m",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3706"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_10k_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWixRh1uh6ru",
        "outputId": "7314f070-b0d8-4292-bbb7-6e0c4526cfbe"
      },
      "id": "iWixRh1uh6ru",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000208, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# movie_10k_df.rename(columns = {'userId':'userID'}, inplace = True)\n",
        "# movie_10k_df.rename(columns = {'movieId':'itemID'}, inplace = True)"
      ],
      "metadata": {
        "id": "ab74VE07Eq1s"
      },
      "id": "ab74VE07Eq1s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjJpU6lTGK51"
      },
      "source": [
        "# Details about dataset"
      ],
      "id": "sjJpU6lTGK51"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpnvsLU_U-7O"
      },
      "outputs": [],
      "source": [
        "summary_df=pd.DataFrame(columns=['Dataset','Algorithm','Sparsity','Precision@k'])"
      ],
      "id": "LpnvsLU_U-7O"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48b485cd"
      },
      "outputs": [],
      "source": [
        "userID=\"userID\"\n",
        "itemID=\"itemID\"\n",
        "score=\"rating\"\n",
        "timestamp='time'"
      ],
      "id": "48b485cd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3enVbN86POhO"
      },
      "source": [
        "# Sparsity "
      ],
      "id": "3enVbN86POhO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnavbMK3Z-7N"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "def checkSparsity(main_df):\n",
        "   \n",
        "    # pivot_df = main_df.pivot_table(\n",
        "    #     index='itemID',\n",
        "    #     columns='userID',\n",
        "    #     values='rating'\n",
        "    # )\n",
        "    totalUsers=main_df.userID.unique().shape[0]\n",
        "    totalitems= main_df.itemID.unique().shape[0]\n",
        "    total=totalUsers*totalitems\n",
        "    totalreconds=main_df.shape[0]\n",
        "    sparsity=(total-totalreconds)/total\n",
        "    return sparsity"
      ],
      "id": "AnavbMK3Z-7N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBbAUd5UBJcn",
        "outputId": "72f62bb7-20e4-4b6e-c8d1-c552e44d1ddd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9553164190519758"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "\n",
        "sparsity_movielens=checkSparsity(movie_10k_df)\n",
        "sparsity_movielens"
      ],
      "id": "zBbAUd5UBJcn"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_sVbpH3tGGfm"
      },
      "id": "_sVbpH3tGGfm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D3Gl4vpp9T2"
      },
      "outputs": [],
      "source": [
        "final_movie_users=len(movie_10k_df.userID.unique())\n",
        "final_movie_items=len(movie_10k_df.itemID.unique())\n",
        "final_movie_rows=movie_10k_df.shape[0]"
      ],
      "id": "-D3Gl4vpp9T2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hVX7fy8DcH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44bb3cb5-8afa-4da4-f598-1071ebe03173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Dataset': 'MovieLens', 'Sparsity': 0.9553164190519758, 'Total Users': 6040, 'Total Items': 3706, 'Total Rows': 1000208}\n"
          ]
        }
      ],
      "source": [
        "df2 = {'Dataset':\"MovieLens\",\\\n",
        "       'Sparsity':sparsity_movielens,\\\n",
        "       'Total Users':final_movie_users,\\\n",
        "       'Total Items':final_movie_items,\\\n",
        "       'Total Rows':final_movie_rows}\n",
        "print(df2)"
      ],
      "id": "8hVX7fy8DcH0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIyREpU8Q_dk"
      },
      "source": [
        "<!-- Observations :\n",
        "1. Very sparse dataset sparsity 0.98\n",
        "2. Many items and users in the dataset has less interaction data -->"
      ],
      "id": "SIyREpU8Q_dk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vudkPURPTki"
      },
      "source": [
        "<!-- ### Divide dataset based on following:\n",
        "- All users rated very few items - will use contant based filtering method.To get threshold value for filtering we first find median of number of rating given by each users.Next choose value less then that median value such that we decrese sparsity as much as possible(less then .95)\n",
        "- For other data we will go with collaborative filtering or other deep learning methods -->"
      ],
      "id": "0vudkPURPTki"
    },
    {
      "cell_type": "code",
      "source": [
        "# movie_10k_df['rating']=1\n",
        "# amazon_df['rating']=1\n",
        "# book_df['rating']=1\n",
        "# food_df['rating']=1\n",
        "# ciao_df['rating']=1\n",
        "# ecommerce_df['rating']=1"
      ],
      "metadata": {
        "id": "GDmSBy60J_YD"
      },
      "id": "GDmSBy60J_YD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow recommenders"
      ],
      "metadata": {
        "id": "aHpgrDyYLe9Z"
      },
      "id": "aHpgrDyYLe9Z"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets"
      ],
      "metadata": {
        "id": "DySpFNPLeYvJ"
      },
      "execution_count": null,
      "outputs": [],
      "id": "DySpFNPLeYvJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import tensorflow_recommenders as tfrs\n",
        "from typing import Dict, Text"
      ],
      "metadata": {
        "id": "etlRCOGlK81S"
      },
      "execution_count": null,
      "outputs": [],
      "id": "etlRCOGlK81S"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "movie_10k_df[\"timestamp\"] = movie_10k_df[\"timestamp\"].astype(int)"
      ],
      "metadata": {
        "id": "ZYq0RG-xVa5m"
      },
      "id": "ZYq0RG-xVa5m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_dict = movie_10k_df[['userID', \n",
        "                                      'itemID',\n",
        "                                      'timestamp'\n",
        "                                      ,'rating'\n",
        "                                      ]]\n",
        "items_dict = movie_10k_df[['itemID']].drop_duplicates()\n"
      ],
      "metadata": {
        "id": "cE6nJ0aOXgSs"
      },
      "execution_count": null,
      "outputs": [],
      "id": "cE6nJ0aOXgSs"
    },
    {
      "cell_type": "code",
      "source": [
        "#rating_dict = {name: np.array(value) for name, value in rating_dict.items()}\n",
        "ratings = tf.data.Dataset.from_tensor_slices(dict(rating_dict))\n",
        "\n",
        "## item features\n",
        "\n",
        "#items_dict = {name: np.array(value) for name, value in items_dict.items()}\n",
        "items = tf.data.Dataset.from_tensor_slices(dict(items_dict))"
      ],
      "metadata": {
        "id": "WLrcdRc6AjCs"
      },
      "id": "WLrcdRc6AjCs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "items"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-JVSi5xWd0U",
        "outputId": "b88e2b4f-4203-48db-f189-e3baebb83141"
      },
      "id": "d-JVSi5xWd0U",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec={'itemID': TensorSpec(shape=(), dtype=tf.string, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in items.take(2).as_numpy_iterator():\n",
        "  print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Von-if-yBfqd",
        "outputId": "40085b6f-5306-4fa1-f37d-925f3bb8347b"
      },
      "id": "Von-if-yBfqd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'itemID': b'661'}\n",
            "{'itemID': b'914'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in ratings.take(2).as_numpy_iterator():\n",
        "  print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dB3UwIsA7ak",
        "outputId": "84eae800-3268-4b72-80a7-d189f036f794"
      },
      "id": "6dB3UwIsA7ak",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'userID': b'1', 'itemID': b'661', 'timestamp': 978302109, 'rating': 3}\n",
            "{'userID': b'1', 'itemID': b'914', 'timestamp': 978301968, 'rating': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Select the basic features.\n",
        "ratings = ratings.map(lambda x: {\n",
        "    'userID' : x['userID'], \n",
        "    'itemID' : x['itemID'], \n",
        "    'timestamp' : x['timestamp'], \n",
        "    'rating' : x['rating'],\n",
        "    \n",
        "})\n",
        "\n",
        "items = items.map(lambda x: x['itemID'])"
      ],
      "metadata": {
        "id": "LsW7Sev1b4Bf"
      },
      "id": "LsW7Sev1b4Bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfPGEcOCcrGP",
        "outputId": "87b2600e-6368-4fc6-c534-c34667b5c5c7"
      },
      "id": "ZfPGEcOCcrGP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset element_spec={'userID': TensorSpec(shape=(), dtype=tf.string, name=None), 'itemID': TensorSpec(shape=(), dtype=tf.string, name=None), 'timestamp': TensorSpec(shape=(), dtype=tf.int64, name=None), 'rating': TensorSpec(shape=(), dtype=tf.int64, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# userIds    = movie_10k_df.userID.unique()\n",
        "# productIds = movie_10k_df.itemID.unique()\n",
        "# total_ratings= len(movie_10k_df.index)"
      ],
      "metadata": {
        "id": "758XFYViZpB-"
      },
      "execution_count": null,
      "outputs": [],
      "id": "758XFYViZpB-"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "user_ids =ratings.batch(1_000_000).map(lambda x: x[\"userID\"])\n",
        "items_list =items.batch(1_000)"
      ],
      "metadata": {
        "id": "0RIC5PJXX8mT"
      },
      "execution_count": null,
      "outputs": [],
      "id": "0RIC5PJXX8mT"
    },
    {
      "cell_type": "code",
      "source": [
        "unique_items = np.unique(np.concatenate(list(items_list),axis =0))\n"
      ],
      "metadata": {
        "id": "9w-NB6o0CFnF"
      },
      "id": "9w-NB6o0CFnF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
      ],
      "metadata": {
        "id": "cQgX9HyJZp2H"
      },
      "id": "cQgX9HyJZp2H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_user_ids[:10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aErTTVCCEuqN",
        "outputId": "6230ee40-f7fe-46e1-836f-74320f7a3b3e"
      },
      "id": "aErTTVCCEuqN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'1', b'10', b'100', b'1000', b'1001', b'1002', b'1003', b'1004',\n",
              "       b'1005', b'1006'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total=ratings.__len__().numpy()\n",
        "train_size=(int) (total * .8 )\n",
        "test_size=(int) (total * .2 )"
      ],
      "metadata": {
        "id": "89VGTaYKX8mU"
      },
      "execution_count": null,
      "outputs": [],
      "id": "89VGTaYKX8mU"
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(total, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(train_size)\n",
        "test = shuffled.skip(train_size).take(test_size)"
      ],
      "metadata": {
        "id": "v6qVBsUhX8mU"
      },
      "execution_count": null,
      "outputs": [],
      "id": "v6qVBsUhX8mU"
    },
    {
      "cell_type": "code",
      "source": [
        "timestamps = np.concatenate(list(ratings.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
        "\n",
        "max_timestamp = timestamps.max()\n",
        "min_timestamp = timestamps.min()\n",
        "\n",
        "timestamp_buckets = np.linspace(\n",
        "    min_timestamp, max_timestamp, num=1000,\n",
        ")\n"
      ],
      "metadata": {
        "id": "3od7QhjaMdEy"
      },
      "id": "3od7QhjaMdEy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tensorflow retrival and Ranking"
      ],
      "metadata": {
        "id": "cMqOpdnDzOJI"
      },
      "id": "cMqOpdnDzOJI"
    },
    {
      "cell_type": "code",
      "source": [
        "class UserModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding_dimension = 32\n",
        "        max_tokens = 10_000\n",
        "\n",
        "        ## user id\n",
        "        self.user_embedding = tf.keras.Sequential([\n",
        "                                                    tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "                                                    vocabulary=unique_user_ids, mask_token=None),\n",
        "                                                    tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
        "                                                    ])\n",
        "       \n",
        "      \n",
        "        self.timestamp_embedding = tf.keras.Sequential([\n",
        "          tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
        "          tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32),\n",
        "        ])\n",
        "        self.normalized_timestamp = tf.keras.layers.Normalization(\n",
        "          axis=None\n",
        "        )\n",
        "\n",
        "        self.normalized_timestamp.adapt(timestamps)\n",
        "\n",
        "        \n",
        "        # self.catagory_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "        #                                                                                 max_tokens=max_tokens)\n",
        "        # self.catagory_text_embedding = tf.keras.Sequential([\n",
        "        #                           self.catagory_vectorizer,\n",
        "        #                           tf.keras.layers.Embedding(max_tokens, self.embedding_dimension, mask_zero=True),\n",
        "        #                           tf.keras.layers.GlobalAveragePooling1D(),\n",
        "        #                         ])\n",
        "\n",
        "        # self.catagory_vectorizer.adapt(category)\n",
        "              \n",
        "        # zip\n",
        "        # self.zip_embedding = tf.keras.Sequential([\n",
        "        #                           tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "        #                             vocabulary=unique_zip, mask_token=None),\n",
        "        #                           tf.keras.layers.Embedding(len(unique_zip) + 1, self.embedding_dimension)\n",
        "        #                         ])\n",
        "        \n",
        "        # self.zip_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "        #                                                                                 max_tokens=max_tokens)\n",
        "        # self.zip_text_embedding = tf.keras.Sequential([\n",
        "        #                           self.zip_vectorizer,\n",
        "        #                           tf.keras.layers.Embedding(max_tokens, self.embedding_dimension, mask_zero=True),\n",
        "        #                           tf.keras.layers.GlobalAveragePooling1D(),\n",
        "        #                         ])\n",
        "\n",
        "        # self.zip_vectorizer.adapt(zip)\n",
        "        \n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Take the input dictionary, pass it through each input layer,\n",
        "        # and concatenate the result.\n",
        "        return tf.concat([\n",
        "            self.user_embedding(inputs[\"userID\"]),\n",
        "            self.timestamp_embedding(inputs[\"timestamp\"]),\n",
        "            tf.reshape(self.normalized_timestamp(inputs[\"timestamp\"]), (-1, 1)),\n",
        "        ], axis=1)"
      ],
      "metadata": {
        "id": "4hG7wh_XPx86"
      },
      "id": "4hG7wh_XPx86",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QueryModel(tf.keras.Model):\n",
        "    \"\"\"Model for encoding user queries.\"\"\"\n",
        "\n",
        "    def __init__(self, layer_sizes, projection_dim=None):\n",
        "        \"\"\"Model for encoding user queries\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # We first use the user model for generating embeddings.\n",
        "        self.embedding_model = UserModel()\n",
        "            \n",
        "        self.dense_layers = tf.keras.Sequential()\n",
        "        for layer_size in layer_sizes[:-1]:\n",
        "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
        "\n",
        "      \n",
        "        for layer_size in layer_sizes[-1:]:\n",
        "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        feature_embedding = self.embedding_model(inputs)\n",
        "        return self.dense_layers(feature_embedding)"
      ],
      "metadata": {
        "id": "9kPoLJebYhW_"
      },
      "id": "9kPoLJebYhW_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ItemModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding_dimension = 32\n",
        "\n",
        "        #max_tokens = 10_000\n",
        "\n",
        "        self.item_embedding = tf.keras.Sequential([\n",
        "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "              vocabulary=unique_items,mask_token=None),\n",
        "          tf.keras.layers.Embedding(len(unique_items) + 1, self.embedding_dimension)\n",
        "        ])\n",
        "\n",
        "        # self.item_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "        #     max_tokens=max_tokens)\n",
        "\n",
        "        # self.item_vectorizer.adapt(items)\n",
        "      \n",
        "    def call(self, items):\n",
        "        return tf.concat([\n",
        "            self.item_embedding(items)\n",
        "         \n",
        "        ], axis=1)"
      ],
      "metadata": {
        "id": "HmTiWaD2YlzJ"
      },
      "id": "HmTiWaD2YlzJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CandidateModel(tf.keras.Model):\n",
        "    \"\"\"Model for encoding items.\"\"\"\n",
        "\n",
        "    def __init__(self, layer_sizes, projection_dim=None):\n",
        "        \"\"\"Model for encoding items.\n",
        "\n",
        "        \n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding_model = ItemModel()\n",
        "\n",
        "         # Then construct the layers.\n",
        "        self.dense_layers = tf.keras.Sequential()\n",
        "\n",
        "        # Use the ReLU activation for all but the last layer.\n",
        "        for layer_size in layer_sizes[:-1]:\n",
        "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
        "\n",
        "        # No activation for the last layer.\n",
        "        for layer_size in layer_sizes[-1:]:\n",
        "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        feature_embedding = self.embedding_model(inputs)\n",
        "        return self.dense_layers(feature_embedding)"
      ],
      "metadata": {
        "id": "dR_Uy7FwRt2y"
      },
      "id": "dR_Uy7FwRt2y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FinalModel(tfrs.models.Model):\n",
        "\n",
        "    def __init__(self, layer_sizes, projection_dim=None ):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.query_model : tf.keras.Model = QueryModel(layer_sizes)\n",
        "        self.candidate_model : tf.keras.Model = CandidateModel(layer_sizes)\n",
        "        \n",
        "        ## rating and retrieval task.\n",
        "        self.layer_sizes=layer_sizes\n",
        "        self.rating_task = tfrs.tasks.Ranking(\n",
        "            loss=tf.keras.losses.MeanSquaredError(),\n",
        "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
        "        )\n",
        "                 \n",
        "        self.retrieval_task : tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
        "            metrics=tfrs.metrics.FactorizedTopK(\n",
        "                candidates=items.batch(128).map(self.candidate_model)\n",
        "            )\n",
        "        )\n",
        "\n",
        "       \n",
        "\n",
        "    def compute_loss(self, features, training=False):\n",
        "        \n",
        "      \n",
        "        ratings = features.pop(\"rating\")\n",
        "        \n",
        "        query_embeddings = self.query_model({\n",
        "            \"userID\": features[\"userID\"],\n",
        "            \"timestamp\": features[\"timestamp\"]\n",
        "        })\n",
        "    \n",
        "        item_embeddings = self.candidate_model(features[\"itemID\"])       \n",
        "        retrieval_loss = self.retrieval_task(query_embeddings, item_embeddings)\n",
        "    \n",
        "    \n",
        "        return self.retrieval_task(query_embeddings, item_embeddings)"
      ],
      "metadata": {
        "id": "9fOA8TGkYxTx"
      },
      "id": "9fOA8TGkYxTx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cached_train = train.shuffle(train_size).batch(26000).cache()\n",
        "\n",
        "cached_test = test.batch(5024).cache()"
      ],
      "metadata": {
        "id": "ihA5Y1zttiR4"
      },
      "id": "ihA5Y1zttiR4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = FinalModel([128,32],\n",
        "                      projection_dim=None)\n",
        "\n"
      ],
      "metadata": {
        "id": "WkMkr2hbY23_"
      },
      "id": "WkMkr2hbY23_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "import time\n",
        "now = time.time()\n",
        "model.fit(cached_train,epochs=1)\n",
        "later = time.time()\n",
        "difference = int(later - now)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Isj2sVoZAtgS",
        "outputId": "d7744ef8-3140-4e81-8642-e25daa167a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 217s 7s/step - root_mean_squared_error: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0020 - factorized_top_k/top_5_categorical_accuracy: 0.0037 - factorized_top_k/top_10_categorical_accuracy: 0.0051 - factorized_top_k/top_50_categorical_accuracy: 0.0134 - factorized_top_k/top_100_categorical_accuracy: 0.0239 - loss: 285096.2529 - regularization_loss: 0.0000e+00 - total_loss: 285096.2529\n"
          ]
        }
      ],
      "id": "Isj2sVoZAtgS"
    },
    {
      "cell_type": "code",
      "source": [
        "print('total time :'+str(difference))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEPrevYIxO-Q",
        "outputId": "62a5af78-36a0-4f54-d818-1247b332ec23"
      },
      "id": "aEPrevYIxO-Q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total time :217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "metrics = model.evaluate(cached_test, return_dict=True)\n",
        "\n",
        "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.5f}.\")\n",
        "print(f\"Retrieval top-50 accuracy: {metrics['factorized_top_k/top_50_categorical_accuracy']:.5f}.\")\n",
        "print(f\"Retrieval top-10 accuracy: {metrics['factorized_top_k/top_10_categorical_accuracy']:.5f}.\")\n",
        "print(f\"Retrieval top-5 accuracy: {metrics['factorized_top_k/top_5_categorical_accuracy']:.5f}.\")\n",
        "print(f\"Retrieval top-1 accuracy: {metrics['factorized_top_k/top_1_categorical_accuracy']:.5f}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KKvqfabl3Cx",
        "outputId": "23b11c2a-70eb-457c-ec99-f45200324c16"
      },
      "id": "6KKvqfabl3Cx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 88s 1s/step - root_mean_squared_error: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 1.9996e-05 - factorized_top_k/top_5_categorical_accuracy: 2.5995e-04 - factorized_top_k/top_10_categorical_accuracy: 7.1985e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0082 - factorized_top_k/top_100_categorical_accuracy: 0.0214 - loss: 42360.8373 - regularization_loss: 0.0000e+00 - total_loss: 42360.8373\n",
            "Retrieval top-100 accuracy: 0.02143.\n",
            "Retrieval top-50 accuracy: 0.00823.\n",
            "Retrieval top-10 accuracy: 0.00072.\n",
            "Retrieval top-5 accuracy: 0.00026.\n",
            "Retrieval top-1 accuracy: 0.00002.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "j9eBkFtafRVn"
      },
      "id": "j9eBkFtafRVn"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# index = tfrs.layers.factorized_top_k.BruteForce(model.query_model)\n",
        "# index.index_from_dataset(\n",
        "#   tf.data.Dataset.zip((items.batch(100), items.batch(100).map(model.candidate_model)))\n",
        "# )\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.query_model)\n",
        "index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((items.batch(100), items.batch(100).map(model.candidate_model)))\n",
        ")\n",
        " \n",
        " \n",
        "_, titles = index({\n",
        "    \"userID\": np.array(['25']),\n",
        "    \"timestamp\": np.array([879024327])},\n",
        "    k=10\n",
        ")\n",
        "titles[0]"
      ],
      "metadata": {
        "id": "rQq4esISmpbq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9be49fa9-c8ab-466b-a12b-94df9d3f6da9"
      },
      "id": "rQq4esISmpbq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b'2168', b'3513', b'3617', b'2916', b'1275', b'1288', b'3756',\n",
              "       b'3597', b'1834', b'2123'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep cross"
      ],
      "metadata": {
        "id": "J9uujZo82ZP4"
      },
      "id": "J9uujZo82ZP4"
    },
    {
      "cell_type": "code",
      "source": [
        "class UserModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding_dimension = 32\n",
        "        max_tokens = 10_000\n",
        "\n",
        "        ## user id\n",
        "        self.user_embedding = tf.keras.Sequential([\n",
        "                                                    tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "                                                    vocabulary=unique_user_ids, mask_token=None),\n",
        "                                                    tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
        "                                                    ])\n",
        "       \n",
        "      \n",
        "        self.timestamp_embedding = tf.keras.Sequential([\n",
        "          tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
        "          tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32),\n",
        "        ])\n",
        "        self.normalized_timestamp = tf.keras.layers.Normalization(\n",
        "          axis=None\n",
        "        )\n",
        "\n",
        "        self.normalized_timestamp.adapt(timestamps)\n",
        "\n",
        "       \n",
        "    def call(self, inputs):\n",
        "        # Take the input dictionary, pass it through each input layer,\n",
        "        # and concatenate the result.\n",
        "        return tf.concat([\n",
        "            self.user_embedding(inputs[\"userID\"]),\n",
        "            self.timestamp_embedding(inputs[\"timestamp\"]),\n",
        "            tf.reshape(self.normalized_timestamp(inputs[\"timestamp\"]), (-1, 1)),\n",
        "        ], axis=1)"
      ],
      "metadata": {
        "id": "zeN195bd2g4Z"
      },
      "execution_count": null,
      "outputs": [],
      "id": "zeN195bd2g4Z"
    },
    {
      "cell_type": "code",
      "source": [
        "class QueryModel(tf.keras.Model):\n",
        "    \"\"\"Model for encoding user queries.\"\"\"\n",
        "\n",
        "    def __init__(self, layer_sizes, projection_dim=None):\n",
        "        \"\"\"Model for encoding user queries\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # We first use the user model for generating embeddings.\n",
        "        self.embedding_model = UserModel()\n",
        "            \n",
        "\n",
        "        # Then construct the layers.\n",
        "        self.dense_layers = tf.keras.Sequential(tfrs.layers.dcn.Cross(projection_dim=projection_dim,\n",
        "                                        kernel_initializer=\"glorot_uniform\"))\n",
        "\n",
        "        # Use the ReLU activation for all but the last layer.\n",
        "        for layer_size in layer_sizes[:-1]:\n",
        "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
        "\n",
        "        # No activation for the last layer.\n",
        "        for layer_size in layer_sizes[-1:]:\n",
        "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        feature_embedding = self.embedding_model(inputs)\n",
        "        return self.dense_layers(feature_embedding)"
      ],
      "metadata": {
        "id": "eafpqCRg2g4Z"
      },
      "execution_count": null,
      "outputs": [],
      "id": "eafpqCRg2g4Z"
    },
    {
      "cell_type": "code",
      "source": [
        "class ItemModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding_dimension = 32\n",
        "\n",
        "        #max_tokens = 10_000\n",
        "\n",
        "        self.item_embedding = tf.keras.Sequential([\n",
        "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "              vocabulary=unique_items,mask_token=None),\n",
        "          tf.keras.layers.Embedding(len(unique_items) + 1, self.embedding_dimension)\n",
        "        ])\n",
        "\n",
        "        # self.item_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "        #     max_tokens=max_tokens)\n",
        "\n",
        "        # self.item_vectorizer.adapt(items)\n",
        "      \n",
        "    def call(self, items):\n",
        "        return tf.concat([\n",
        "            self.item_embedding(items)\n",
        "         \n",
        "        ], axis=1)"
      ],
      "metadata": {
        "id": "3A_q-G5b2g4Z"
      },
      "execution_count": null,
      "outputs": [],
      "id": "3A_q-G5b2g4Z"
    },
    {
      "cell_type": "code",
      "source": [
        "class CandidateModel(tf.keras.Model):\n",
        "    \"\"\"Model for encoding items.\"\"\"\n",
        "\n",
        "    def __init__(self, layer_sizes, projection_dim=None):\n",
        "        \"\"\"Model for encoding items.\n",
        "\n",
        "        \n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding_model = ItemModel()\n",
        "\n",
        "         # Then construct the layers.\n",
        "        self.dense_layers = tf.keras.Sequential(tfrs.layers.dcn.Cross(projection_dim=projection_dim,\n",
        "                                                kernel_initializer=\"glorot_uniform\"))\n",
        "\n",
        "        # Use the ReLU activation for all but the last layer.\n",
        "        for layer_size in layer_sizes[:-1]:\n",
        "            self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
        "\n",
        "        # No activation for the last layer.\n",
        "        for layer_size in layer_sizes[-1:]:\n",
        "            self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        feature_embedding = self.embedding_model(inputs)\n",
        "        return self.dense_layers(feature_embedding)"
      ],
      "metadata": {
        "id": "a93bCJMJ2g4Z"
      },
      "execution_count": null,
      "outputs": [],
      "id": "a93bCJMJ2g4Z"
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossDNNModel(tfrs.models.Model):\n",
        "\n",
        "    def __init__(self, layer_sizes,projection_dim=None ):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.query_model : tf.keras.Model = QueryModel(layer_sizes)\n",
        "        self.candidate_model : tf.keras.Model = CandidateModel(layer_sizes)\n",
        "        \n",
        "        ## rating and retrieval task.\n",
        "        \n",
        "        self.rating_task = tfrs.tasks.Ranking(\n",
        "            loss=tf.keras.losses.MeanSquaredError(),\n",
        "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
        "        )\n",
        "                 \n",
        "        self.retrieval_task : tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
        "            metrics=tfrs.metrics.FactorizedTopK(\n",
        "                candidates=items.batch(128).map(self.candidate_model)\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "    def compute_loss(self, features, training=False):\n",
        "        \n",
        "        \n",
        "        ratings = features.pop(\"rating\")\n",
        "        \n",
        "        query_embeddings = self.query_model({\n",
        "            \"userID\": features[\"userID\"],\n",
        "            \"timestamp\": features[\"timestamp\"],\n",
        "        })\n",
        "    \n",
        "        item_embeddings = self.candidate_model(features[\"itemID\"])       \n",
        "        retrieval_loss = self.retrieval_task(query_embeddings, item_embeddings)\n",
        "    \n",
        "    \n",
        "        return self.retrieval_task(query_embeddings, item_embeddings)"
      ],
      "metadata": {
        "id": "kbXVsh0ulNpZ"
      },
      "id": "kbXVsh0ulNpZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = CrossDNNModel([128,32],\n",
        "                      projection_dim=None)\n",
        "\n"
      ],
      "metadata": {
        "id": "pLEjaiRu3VaM"
      },
      "execution_count": null,
      "outputs": [],
      "id": "pLEjaiRu3VaM"
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "import time\n",
        "now = time.time()\n",
        "model.fit(cached_train,epochs=1)\n",
        "later = time.time()\n",
        "difference = int(later - now)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05452b6c-ba1c-42eb-bfd4-ab3e75072054",
        "id": "GIsTzcfQ3VaN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 201s 6s/step - root_mean_squared_error: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0117 - factorized_top_k/top_5_categorical_accuracy: 0.0172 - factorized_top_k/top_10_categorical_accuracy: 0.0213 - factorized_top_k/top_50_categorical_accuracy: 0.0459 - factorized_top_k/top_100_categorical_accuracy: 0.0716 - loss: 330097.3633 - regularization_loss: 0.0000e+00 - total_loss: 330097.3633\n"
          ]
        }
      ],
      "id": "GIsTzcfQ3VaN"
    },
    {
      "cell_type": "code",
      "source": [
        "print('total time :'+str(difference))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc5ce5e5-c55f-4186-8f64-045d745c6b67",
        "id": "DQ6JYckX3VaO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total time :201\n"
          ]
        }
      ],
      "id": "DQ6JYckX3VaO"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "metrics = model.evaluate(cached_test, return_dict=True)\n",
        "\n",
        "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.5f}.\")\n",
        "print(f\"Retrieval top-50 accuracy: {metrics['factorized_top_k/top_50_categorical_accuracy']:.5f}.\")\n",
        "print(f\"Retrieval top-10 accuracy: {metrics['factorized_top_k/top_10_categorical_accuracy']:.5f}.\")\n",
        "print(f\"Retrieval top-5 accuracy: {metrics['factorized_top_k/top_5_categorical_accuracy']:.5f}.\")\n",
        "print(f\"Retrieval top-1 accuracy: {metrics['factorized_top_k/top_1_categorical_accuracy']:.5f}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74c661a-406d-427a-f688-2908c14080b8",
        "id": "juGhz_003VaP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 55s 1s/step - root_mean_squared_error: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 3.8492e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0029 - factorized_top_k/top_10_categorical_accuracy: 0.0060 - factorized_top_k/top_50_categorical_accuracy: 0.0276 - factorized_top_k/top_100_categorical_accuracy: 0.0490 - loss: 42403.4554 - regularization_loss: 0.0000e+00 - total_loss: 42403.4554\n",
            "Retrieval top-100 accuracy: 0.04903.\n",
            "Retrieval top-50 accuracy: 0.02757.\n",
            "Retrieval top-10 accuracy: 0.00600.\n",
            "Retrieval top-5 accuracy: 0.00291.\n",
            "Retrieval top-1 accuracy: 0.00038.\n"
          ]
        }
      ],
      "id": "juGhz_003VaP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "WfXrt-zQ3VaR"
      },
      "id": "WfXrt-zQ3VaR"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.query_model)\n",
        "index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((items.batch(100), items.batch(100).map(model.candidate_model)))\n",
        ")\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.query_model)\n",
        "index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((items.batch(100), items.batch(100).map(model.candidate_model)))\n",
        ")\n",
        " \n",
        " \n",
        "_, titles = index({\n",
        "    \"userID\": np.array(['25']),\n",
        "    \"timestamp\": np.array([879024327])},\n",
        "    k=10\n",
        ")\n",
        "titles[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5377cf9-110f-4a91-f1f6-35d1c1855a31",
        "id": "csYV4hvY3VaR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "array([b'3830', b'1842', b'228', b'3905', b'2930', b'1181', b'447',\n",
              "       b'808', b'131', b'3652'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "id": "csYV4hvY3VaR"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "sjJpU6lTGK51",
        "3enVbN86POhO"
      ]
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}